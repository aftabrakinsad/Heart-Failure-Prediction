# -*- coding: utf-8 -*-
"""KNN_Statistical_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fDP6Vij6x8sH8onA4rhKgkwQDXxYQJdb
"""

!pip install optuna

import optuna
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

X_train = pd.read_csv('/content/X_train_final.csv').values
y_train = pd.read_csv('/content/y_train_final.csv').values.astype(np.float32).flatten()

X_val = pd.read_csv('/content/X_val_processed.csv').values
y_val = pd.read_csv('/content/y_val_processed.csv').values.astype(np.float32).flatten()

X_combined_for_cv = np.concatenate((X_train, X_val), axis=0)
y_combined_for_cv = np.concatenate((y_train, y_val), axis=0)

print(f"Shape of X_train for Optuna: {X_train.shape}, y_train: {y_train.shape}")
print(f"Shape of X_val for Optuna: {X_val.shape}, y_val: {y_val.shape}")
print(f"Shape of X_combined_for_cv for KFold: {X_combined_for_cv.shape}, y_combined_for_cv: {y_combined_for_cv.shape}")

def objective_knn(trial):
    n_neighbors = trial.suggest_int('n_neighbors', 3, 30)
    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])
    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])

    if metric == 'minkowski':
        p = trial.suggest_int('p', 1, 3)
        knn_model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, metric=metric, p=p)
    else:
        knn_model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, metric=metric)

    knn_model.fit(X_train, y_train)

    y_pred_proba_val = knn_model.predict_proba(X_val)[:, 1]

    if len(np.unique(y_val)) > 1:
        val_auc = roc_auc_score(y_val, y_pred_proba_val)
        val_loss = 1.0 - val_auc
    else:
        return float('inf')

    return val_loss

print("\n--- Starting Optuna Optimization Study for KNN Baseline (Minimizing 1-AUC) ---")
study_knn = optuna.create_study(direction='minimize', study_name='KNN_Optimization',
                                pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10))
study_knn.optimize(objective_knn, n_trials=200, show_progress_bar=True)

print("\n--- KNN Optimization Finished ---")
print(f"Number of finished trials: {len(study_knn.trials)}")
print(f"Best trial value: {study_knn.best_trial.value:.4f}")
print(f"Corresponding Best Validation AUC: {1 - study_knn.best_trial.value:.4f}")
print("Best KNN hyperparameters:")
best_params_knn = study_knn.best_trial.params
for key, value in best_params_knn.items():
    print(f"  {key}: {value}")

n_splits = 10
kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

knn_accuracy_scores = []
knn_auc_scores = []
knn_precision_scores = []
knn_recall_scores = []
knn_f1_scores = []

print(f"\n--- Starting {n_splits}-Fold Cross-Validation for Optimized KNN Baseline ---")

for fold, (train_index, val_index) in enumerate(kf.split(X_combined_for_cv, y_combined_for_cv)):
    print(f"\n--- Fold {fold+1}/{n_splits} ---")
    X_train_fold, X_val_fold = X_combined_for_cv[train_index], X_combined_for_cv[val_index]
    y_train_fold, y_val_fold = y_combined_for_cv[train_index], y_combined_for_cv[val_index]

    single_class_in_val_fold = (len(np.unique(y_val_fold)) <= 1)
    if single_class_in_val_fold:
        print(f"WARNING: Fold {fold+1} validation set contains only one class. AUC will be NaN.")

    if best_params_knn['metric'] == 'minkowski':
        knn_model_cv = KNeighborsClassifier(
            n_neighbors=best_params_knn['n_neighbors'],
            weights=best_params_knn['weights'],
            metric=best_params_knn['metric'],
            p=best_params_knn['p']
        )
    else:
        knn_model_cv = KNeighborsClassifier(
            n_neighbors=best_params_knn['n_neighbors'],
            weights=best_params_knn['weights'],
            metric=best_params_knn['metric']
        )

    knn_model_cv.fit(X_train_fold, y_train_fold)

    y_pred_proba_knn = knn_model_cv.predict_proba(X_val_fold)[:, 1]
    y_pred_class_knn = knn_model_cv.predict(X_val_fold)

    knn_accuracy_scores.append(accuracy_score(y_val_fold, y_pred_class_knn))
    if not single_class_in_val_fold:
        knn_auc_scores.append(roc_auc_score(y_val_fold, y_pred_proba_knn))
    else:
        knn_auc_scores.append(np.nan)
    knn_precision_scores.append(precision_score(y_val_fold, y_pred_class_knn, zero_division=0))
    knn_recall_scores.append(recall_score(y_val_fold, y_pred_class_knn, zero_division=0))
    knn_f1_scores.append(f1_score(y_val_fold, y_pred_class_knn, zero_division=0))

    print(f"  KNN Baseline Fold {fold+1} Metrics:")
    print(f"    Accuracy: {knn_accuracy_scores[-1]:.4f}")
    print(f"    AUC: {knn_auc_scores[-1]:.4f}" if not np.isnan(knn_auc_scores[-1]) else "AUC: N/A")
    print(f"    Precision: {knn_precision_scores[-1]:.4f}")
    print(f"    Recall: {knn_recall_scores[-1]:.4f}")
    print(f"    F1-Score: {knn_f1_scores[-1]:.4f}")

print("--- Optimized KNN Baseline: 10-Fold Cross-Validation Results (Mean ± Standard Deviation) ---")
print(f"Accuracy: {np.nanmean(knn_accuracy_scores):.4f} ± {np.nanstd(knn_accuracy_scores):.4f}")
print(f"AUC: {np.nanmean(knn_auc_scores):.4f} ± {np.nanstd(knn_auc_scores):.4f}")
print(f"Precision: {np.nanmean(knn_precision_scores):.4f} ± {np.nanstd(knn_precision_scores):.4f}")
print(f"Recall: {np.nanmean(knn_recall_scores):.4f} ± {np.nanstd(knn_recall_scores):.4f}")
print(f"F1-Score: {np.nanmean(knn_f1_scores):.4f} ± {np.nanstd(knn_f1_scores):.4f}")

def bootstrap_confidence_interval(data, alpha=0.95, n_bootstraps=10000):
    if len(data) == 0 or np.all(np.isnan(data)):
        return (np.nan, np.nan)

    data = np.array(data)[~np.isnan(data)]
    if len(data) == 0:
        return (np.nan, np.nan)

    bootstrap_means = []
    for _ in range(n_bootstraps):
        sample = np.random.choice(data, size=len(data), replace=True)
        bootstrap_means.append(np.mean(sample))

    lower_percentile = (1 - alpha) / 2 * 100
    upper_percentile = (1 + alpha) / 2 * 100

    lower_bound = np.percentile(bootstrap_means, lower_percentile)
    upper_bound = np.percentile(bootstrap_means, upper_percentile)

    return (lower_bound, upper_bound)

print("\n--- Optimized KNN Baseline: 95% Confidence Intervals (from 10-Fold CV) ---")
ci_knn_accuracy = bootstrap_confidence_interval(knn_accuracy_scores)
ci_knn_auc = bootstrap_confidence_interval(knn_auc_scores)
ci_knn_precision = bootstrap_confidence_interval(knn_precision_scores)
ci_knn_recall = bootstrap_confidence_interval(knn_recall_scores)
ci_knn_f1 = bootstrap_confidence_interval(knn_f1_scores)

print(f"Accuracy CI: ({ci_knn_accuracy[0]:.4f}, {ci_knn_accuracy[1]:.4f})")
print(f"AUC CI: ({ci_knn_auc[0]:.4f}, {ci_knn_auc[1]:.4f})")
print(f"Precision CI: ({ci_knn_precision[0]:.4f}, {ci_knn_precision[1]:.4f})")
print(f"Recall CI: ({ci_knn_recall[0]:.4f}, {ci_knn_recall[1]:.4f})")
print(f"F1-Score CI: ({ci_knn_f1[0]:.4f}, {ci_knn_f1[1]:.4f})")